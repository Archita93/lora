{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52921e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/51/4b/a59464ee5f77822a81ee069b4021163a0174940a92685efc3cf8b4c443a3/openai-1.82.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Obtaining dependency information for anyio<5,>=3.5.0 from https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/be/cf/fc33f5159ce132be1d8dd57251a1ec7a631c7df4bd11e1cd198308c6ae32/jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/b5/69/831ed22b38ff9b4b64b66569f0e5b7b97cf3638346eb95a2147fdb49ad5f/pydantic-2.11.5-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio (from openai)\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in ./lor_venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./lor_venv/lib/python3.11/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./lor_venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./lor_venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for h11>=0.16 from https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for pydantic-core==2.33.2 from https://files.pythonhosted.org/packages/24/2f/3cfa7244ae292dd850989f328722d2aef313f74ffc471184dc509e1e4e5a/pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for typing-inspection>=0.4.0 from https://files.pythonhosted.org/packages/17/69/cd203477f944c353c31bade965f880aa1061fd6bf05ded0726ca845b6ff7/typing_inspection-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl (321 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.82.0 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 typing-inspection-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./lor_venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./lor_venv/lib/python3.11/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lor_venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lor_venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lor_venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./lor_venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/25/92/ee1d7a00bb6b8c55755d4984fd82608603a3cc59959245068ce32e7fb808/scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./lor_venv/lib/python3.11/site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.6.0 from https://files.pythonhosted.org/packages/4a/4a/66ba30abe5ad1a3ad15bfb0b59d22174012e8056ff448cb1644deccbfed2/scipy-1.15.3-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading scipy-1.15.3-cp311-cp311-macosx_12_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/7d/4f/1195bbac8e0c2acc5f740661631d8d750dc38d4a32b23ee5df3cde6f4e0d/joblib-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-macosx_12_0_arm64.whl (30.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/c2/86/e1c86690610661cd716eda5f9d0b35eaf606ae6c9b6736687cfc8f2d0cd8/matplotlib-3.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/e6/75/3469f011d64b8bbfa04f709bfc23e1dd71be54d05b1b083be9f5b22750d1/contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/76/2e/9b9bd943872a50cb182382f8f4a99af92d76e800603d5f73e4343fdce61a/fonttools-4.58.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading fonttools-4.58.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (104 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/5f/b4/c12b3ac0852a3a68f94598d4c8d569f55361beef6159dce4e7b624160da2/kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./lor_venv/lib/python3.11/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lor_venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./lor_venv/lib/python3.11/site-packages (from matplotlib) (11.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/05/e7/df2285f3d08fee213f2d041540fa4fc9ca6c2d44cf36d3a035bf2a8d2bcc/pyparsing-3.2.3-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./lor_venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./lor_venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.6/254.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e57df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Obtaining dependency information for faker from https://files.pythonhosted.org/packages/ce/99/045b2dae19a01b9fbb23b9971bc04f4ef808e7f3a213d08c81067304a210/faker-37.3.0-py3-none-any.whl.metadata\n",
      "  Downloading faker-37.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting nlpaug\n",
      "  Obtaining dependency information for nlpaug from https://files.pythonhosted.org/packages/1c/28/a799de8b713e7cf84214d48739d0343505ff0967f85055b82d65894e1d02/nlpaug-1.1.11-py3-none-any.whl.metadata\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/03/2a/43afac516eb82409ca47d7206f982beaf265d2ba06a72ca07cf06b290c20/spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: tzdata in ./lor_venv/lib/python3.11/site-packages (from faker) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in ./lor_venv/lib/python3.11/site-packages (from nlpaug) (2.2.5)\n",
      "Requirement already satisfied: pandas>=1.2.0 in ./lor_venv/lib/python3.11/site-packages (from nlpaug) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.22.0 in ./lor_venv/lib/python3.11/site-packages (from nlpaug) (2.32.3)\n",
      "Collecting gdown>=4.0.0 (from nlpaug)\n",
      "  Obtaining dependency information for gdown>=4.0.0 from https://files.pythonhosted.org/packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/14/b0/3ee762e98cf9a8c2df9c8b377c326f3dd4495066d4eace9066fca46eba7a/murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/41/b4/7546faf2ab63e59befc95972316d62276cec153f7d4d60e7b0d5e08f0602/cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/a8/b3/1a73ba16bab53043fd19dd0a7838ae05c705dccb329404dd4ad5925767f1/preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.4.0,>=8.3.4 from https://files.pythonhosted.org/packages/f0/53/5f9eeb725c2ca94adef76a2cd0289bc530728b0a035eed815c766a9291ef/thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/41/47/1bdaad84502df973ecb8ca658117234cf7fb20e1dec60da71dce82de993f/srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/c9/62/d4ba7afe2096d5659ec3db8b15d8665bdcb92a3c6ff0b95e99895b335a9c/typer-0.15.4-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./lor_venv/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./lor_venv/lib/python3.11/site-packages (from spacy) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in ./lor_venv/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./lor_venv/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lor_venv/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/c3/6b/068c2ea7a712bf805c62445bd9e9c06d7340358ef2824150eceac027444b/langcodes-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting beautifulsoup4 (from gdown>=4.0.0->nlpaug)\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/50/cd/30110dc0ffcf3b131156077b90e9f60ed75711223f306da4db08eff8403b/beautifulsoup4-4.13.4-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in ./lor_venv/lib/python3.11/site-packages (from gdown>=4.0.0->nlpaug) (3.18.0)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/5d/e9/5a5ffd9b286db82be70d677d0a91e4d58f7912bb8dd026ddeeb4abe70679/language_data-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lor_venv/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lor_venv/lib/python3.11/site-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./lor_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./lor_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./lor_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./lor_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lor_venv/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lor_venv/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lor_venv/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lor_venv/lib/python3.11/site-packages (from requests>=2.22.0->nlpaug) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for blis<1.4.0,>=1.3.0 from https://files.pythonhosted.org/packages/c1/13/a3b66fd57c75343a5b2e6323cd8f73bdd2e9b328deba7cf676ec334ec754/blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click<8.2,>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for click<8.2,>=8.0.0 from https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/40/e7/6fea57b887f8e367c1e4a496ba03bfaf57824b766f777723ce1faf28834b/cloudpathlib-0.21.1-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for smart-open<8.0.0,>=5.2.1 from https://files.pythonhosted.org/packages/7a/18/9a8d9f01957aa1f8bbc5676d54c2e33102d247e146c1a3679d3bd5cc2e3a/smart_open-7.1.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lor_venv/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for marisa-trie>=1.1.0 from https://files.pythonhosted.org/packages/e8/04/87dd0840f3f720e511eba56193c02bf64d7d96df1ca9f6d19994f55154be/marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./lor_venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./lor_venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/65/46/5a917ce85b5c3b490d35c02bf71aedaa9f2f63f2d15d9949cc4ba56e8ba9/wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=4.0.0->nlpaug)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/e7/9c/0e6afc12c269578be5c0c1c9f4b49a8d32770a080260c333ac04cc1c832d/soupsieve-2.7-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests>=2.22.0->nlpaug)\n",
      "  Obtaining dependency information for PySocks!=1.5.7,>=1.5.6 from https://files.pythonhosted.org/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl.metadata\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading faker-37.3.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl (845 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.3/845.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, soupsieve, shellingham, PySocks, murmurhash, mdurl, marisa-trie, faker, cloudpathlib, click, catalogue, blis, srsly, smart-open, preshed, markdown-it-py, language-data, beautifulsoup4, rich, langcodes, gdown, confection, typer, thinc, nlpaug, weasel, spacy\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.4 blis-1.3.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 faker-37.3.0 gdown-5.2.0 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.13 nlpaug-1.1.11 preshed-3.0.9 rich-14.0.0 shellingham-1.5.4 smart-open-7.1.0 soupsieve-2.7 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.15.4 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker nlpaug spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c76f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "fake = Faker()\n",
    "Faker.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c36798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_mammography_report():\n",
    "    hospitals = [\n",
    "        (\"Downtown Breast Imaging Center\", \"123 Main St, Cityville, State\"),\n",
    "        (\"Westside Women's Imaging Clinic\", \"456 Oak Ave, Townsville, State\"),\n",
    "        (\"Eastside Diagnostic Center\", \"789 Pine Rd, Villagetown, State\"),\n",
    "        (\"Central Breast Health Facility\", \"101 Maple Blvd, Metrocity, State\"),\n",
    "    ]\n",
    "\n",
    "    patient_locations = [\n",
    "        \"Cityville\",\n",
    "        \"Townsville\",\n",
    "        \"Villagetown\",\n",
    "        \"Metrocity\",\n",
    "        \"Lakeside\",\n",
    "        \"Hilltown\"\n",
    "    ]\n",
    "\n",
    "    hospital_name, hospital_location = random.choice(hospitals)\n",
    "    patient_location = random.choice(patient_locations)\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=40, maximum_age=75).strftime(\"%B %d, %Y\")\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    mrn = fake.bothify(text=\"#####\")\n",
    "    ssn = fake.ssn()\n",
    "    health_plan_id = fake.bothify(text=\"########\")\n",
    "    account_number = fake.bothify(text=\"#######\")\n",
    "    license_number = fake.bothify(text=\"#######\")\n",
    "    certificate_number = fake.bothify(text=\"#####\")\n",
    "    license_plate = fake.bothify(text=\"???###\")\n",
    "    vehicle_id = fake.bothify(text=\"########\")\n",
    "    device_serial = fake.bothify(text=\"DEV-SN-######\")\n",
    "    scan_date = fake.date()\n",
    "    scan_type = random.choice([\"screening mammogram\", \"diagnostic mammogram\"])\n",
    "    laterality = random.choice([\"left\", \"right\", \"bilateral\"])\n",
    "    findings = random.choice([\n",
    "        \"no suspicious findings\",\n",
    "        \"a focal asymmetry in the upper outer quadrant\",\n",
    "        \"scattered fibroglandular densities\",\n",
    "        \"a well-circumscribed mass likely benign\",\n",
    "        \"an area of architectural distortion requiring further evaluation\"\n",
    "    ])\n",
    "\n",
    "    birads = random.choice([\n",
    "        \"BI-RADS 1 (Negative)\", \n",
    "        \"BI-RADS 2 (Benign)\", \n",
    "        \"BI-RADS 3 (Probably benign)\",\n",
    "        \"BI-RADS 4 (Suspicious abnormality)\",\n",
    "        \"BI-RADS 5 (Highly suggestive of malignancy)\"\n",
    "    ])\n",
    "    follow_up = random.choice([\n",
    "        \"Annual screening recommended.\",\n",
    "        \"Ultrasound follow-up in 6 months.\",\n",
    "        \"Biopsy recommended for further evaluation.\",\n",
    "        \"Short interval follow-up advised.\"\n",
    "    ])\n",
    "\n",
    "    templates =  [\n",
    "    f\"\"\"\n",
    "On {scan_date}, {name} (born {dob}, SSN: {ssn}) underwent a {scan_type} of the {laterality} breast. \n",
    "The scan was interpreted by Dr. {doctor} at {hospital_name} in {hospital_location}. \n",
    "Findings: {findings}. Breast density was normal. \n",
    "BI-RADS assessment: {birads}. Follow-up recommendation: {follow_up}. \n",
    "Patient resides at {address}, originally from {patient_location}. \n",
    "Contact: {phone}, {email}. MRN: {mrn}, Health Plan ID: {health_plan_id}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "{hospital_name} ({hospital_location}) conducted a {scan_type} on {scan_date} for {name} (DOB: {dob}, License #: {license_number}). \n",
    "Dr. {doctor} reviewed the {laterality} breast images and noted {findings}. Density: normal. \n",
    "BI-RADS: {birads}. Follow-up: {follow_up}. \n",
    "Patient lives at {address}, hometown: {patient_location}. \n",
    "Reachable at {phone} / {email}. MRN: {mrn}, Account #: {account_number}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "On {scan_date}, {name} (DOB {dob}, SSN: {ssn}) underwent a {scan_type} of the {laterality} breast at {hospital_name}, {hospital_location}. \n",
    "Dr. {doctor} interpreted the results, observing {findings}. \n",
    "Breast tissue showed standard density. BI-RADS score: {birads}. \n",
    "Follow-up instructions: {follow_up}. \n",
    "Patient’s medical identifiers include MRN {mrn}, Health Plan ID {health_plan_id}, and License Plate {license_plate}. \n",
    "Contact details: {phone}, {email}. Current residence: {address}, originally from {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "{scan_date}: {name} (DOB: {dob}) underwent a {scan_type} focused on the {laterality} breast. \n",
    "Conducted at {hospital_name} ({hospital_location}), results interpreted by Dr. {doctor}. \n",
    "Findings: {findings}, density: normal. BI-RADS: {birads}. \n",
    "Patient has the following identifiers on file: MRN {mrn}, SSN {ssn}, Certificate # {certificate_number}. \n",
    "Recommended follow-up: {follow_up}. \n",
    "Reachable at {phone}, {email}, residing at {address}, from {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "On {scan_date}, {name} (DOB {dob}) had a {scan_type} examining the {laterality} breast. \n",
    "Performed by Dr. {doctor} at {hospital_name}, {hospital_location}. \n",
    "Results: {findings}, with no abnormal density noted. BI-RADS category {birads}. \n",
    "Patient identifiers: MRN {mrn}, SSN {ssn}, Health Plan Beneficiary #: {health_plan_id}, Vehicle ID: {vehicle_id}. \n",
    "Follow-up plan: {follow_up}. Contact via phone: {phone}, email: {email}, residing at {address}, originally from {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "A {scan_type} was performed on {scan_date} for {name} (DOB {dob}, SSN {ssn}, License # {license_number}). \n",
    "Imaging of the {laterality} breast was interpreted by Dr. {doctor} at {hospital_name} in {hospital_location}. \n",
    "Findings included: {findings}. Breast density within expected range. \n",
    "BI-RADS assessment: {birads}, follow-up required: {follow_up}. \n",
    "The patient can be contacted at {phone}, {email}; residence: {address}; MRN: {mrn}; originating from {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "{hospital_name}, located in {hospital_location}, conducted a {scan_type} of the {laterality} breast on {scan_date} for {name} (DOB: {dob}). \n",
    "Dr. {doctor} interpreted the images, which showed {findings}. \n",
    "Breast tissue was of normal density. BI-RADS score: {birads}. \n",
    "Patient's known identifiers: MRN {mrn}, Account #: {account_number}, Device Serial #: {device_serial}. \n",
    "Next steps include: {follow_up}. Reach out via {phone}, {email}. Current address: {address}, originally from {patient_location}.\n",
    "    \"\"\"\n",
    "]\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans with your 6 entity categories:\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (scan_date, \"DATE\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (hospital_location, \"LOCATION\"),\n",
    "        (patient_location, \"LOCATION\"),\n",
    "        (hospital_name, \"HOSPITAL\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (ssn, \"ID\"),\n",
    "        (health_plan_id, \"ID\"),\n",
    "        (account_number, \"ID\"),\n",
    "        (license_number, \"ID\"),\n",
    "        (certificate_number, \"ID\"),\n",
    "        (license_plate, \"ID\"),\n",
    "        (vehicle_id, \"ID\"),\n",
    "        (device_serial, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "    ]:  \n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bff81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central Imaging Clinic in 101 Xray Ave, Metrocity, State received imaging studies for Kathy Hines (born January 04, 1941) on 2014-06-24. \n",
      "    A non-contrast CT scan was performed on the abdomen due to acute abdominal pain, with Dr. Diamond Taylor interpreting the results. \n",
      "    Notable findings include no acute intracranial hemorrhage or mass effect, with the final impression being hepatomegaly likely secondary to fatty infiltration. \n",
      "    For follow-up, contact details are: phone 7403363445, email michaelsmith@example.com. The patient resides at 432 Miller Dam, South Christina, UT 20046 and is originally from Hilltown. MRN: MRN-45127.\n",
      "[{'start': 86, 'end': 97, 'label': 'NAME', 'text': 'Kathy Hines'}, {'start': 104, 'end': 120, 'label': 'DATE', 'text': 'January 04, 1941'}, {'start': 232, 'end': 246, 'label': 'NAME', 'text': 'Diamond Taylor'}, {'start': 551, 'end': 592, 'label': 'LOCATION', 'text': '432 Miller Dam, South Christina, UT 20046'}, {'start': 0, 'end': 22, 'label': 'HOSPITAL', 'text': 'Central Imaging Clinic'}, {'start': 26, 'end': 56, 'label': 'LOCATION', 'text': '101 Xray Ave, Metrocity, State'}, {'start': 631, 'end': 640, 'label': 'ID', 'text': 'MRN-45127'}, {'start': 484, 'end': 494, 'label': 'CONTACT', 'text': '7403363445'}, {'start': 502, 'end': 526, 'label': 'CONTACT', 'text': 'michaelsmith@example.com'}]\n"
     ]
    }
   ],
   "source": [
    "def generate_ct_scan_report():\n",
    "    imaging_centers = [\n",
    "        (\"City Medical Imaging Center\", \"123 Radiology St, Metropolis, State\"),\n",
    "        (\"Westside Diagnostic Imaging\", \"456 Scan Blvd, Townsville, State\"),\n",
    "        (\"Eastside Imaging Facility\", \"789 CT Rd, Villagetown, State\"),\n",
    "        (\"Central Imaging Clinic\", \"101 Xray Ave, Metrocity, State\"),\n",
    "    ]\n",
    "\n",
    "    patient_locations = [\n",
    "        \"Metropolis\",\n",
    "        \"Townsville\",\n",
    "        \"Villagetown\",\n",
    "        \"Metrocity\",\n",
    "        \"Lakeside\",\n",
    "        \"Hilltown\"\n",
    "    ]\n",
    "\n",
    "    imaging_center, center_location = random.choice(imaging_centers)\n",
    "    patient_location = random.choice(patient_locations)\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=20, maximum_age=90).strftime(\"%B %d, %Y\")\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    ssn = fake.ssn()\n",
    "    health_plan_id = fake.bothify(text=\"HP-########\")\n",
    "    account_number = fake.bothify(text=\"ACCT-#######\")\n",
    "    license_number = fake.bothify(text=\"LIC-#######\")\n",
    "    certificate_number = fake.bothify(text=\"CERT-#####\")\n",
    "    license_plate = fake.bothify(text=\"PLATE-???###\")\n",
    "    vehicle_id = fake.bothify(text=\"VEH-########\")\n",
    "    device_serial = fake.bothify(text=\"DEV-SN-######\")\n",
    "    mrn = fake.bothify(text=\"#####\")\n",
    "    scan_date = fake.date()\n",
    "    scan_type = random.choice([\"non-contrast CT scan\", \"contrast-enhanced CT scan\"])\n",
    "    body_part = random.choice([\"head\", \"chest\", \"abdomen\", \"pelvis\"])\n",
    "    indication = random.choice([\n",
    "        \"trauma evaluation\",\n",
    "        \"suspected infection\",\n",
    "        \"cancer staging\",\n",
    "        \"acute abdominal pain\",\n",
    "        \"follow-up of known pathology\"\n",
    "    ])\n",
    "    findings = random.choice([\n",
    "        \"no acute intracranial hemorrhage or mass effect\",\n",
    "        \"small right lower lobe pneumonia\",\n",
    "        \"no evidence of bowel obstruction or free air\",\n",
    "        \"mild hepatomegaly with no focal lesions\",\n",
    "        \"enlarged lymph nodes in the mediastinum\"\n",
    "    ])\n",
    "    impression = random.choice([\n",
    "        \"normal study\",\n",
    "        \"findings consistent with pneumonia\",\n",
    "        \"no acute abdominal pathology detected\",\n",
    "        \"hepatomegaly likely secondary to fatty infiltration\",\n",
    "        \"lymphadenopathy requires further evaluation\"\n",
    "    ])\n",
    "\n",
    "    templates = [\n",
    "        f\"\"\"\n",
    "        On {scan_date}, {name} (DOB: {dob}) underwent a {scan_type} targeting the {body_part}, indicated by {indication}. \n",
    "        The images were carefully reviewed by Dr. {doctor} at {imaging_center}, situated in {center_location}. \n",
    "        Key findings: {findings}. Impression rendered: {impression}. \n",
    "        The patient currently lives at {address}, hailing from {patient_location}. They can be reached at {phone} or via email at {email}. MRN: {mrn}.\n",
    "            \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "    {imaging_center} in {center_location} received imaging studies for {name} (born {dob}) on {scan_date}. \n",
    "    A {scan_type} was performed on the {body_part} due to {indication}, with Dr. {doctor} interpreting the results. \n",
    "    Notable findings include {findings}, with the final impression being {impression}. \n",
    "    For follow-up, contact details are: phone {phone}, email {email}. The patient resides at {address} and is originally from {patient_location}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "    Patient {name}, DOB {dob}, had a {scan_type} on the {body_part} dated {scan_date}, prompted by {indication}. \n",
    "    Dr. {doctor} of {imaging_center} ({center_location}) evaluated the images, documenting {findings}. \n",
    "    The concluding impression was {impression}. \n",
    "    Reachable at {phone} or {email}, the patient lives at {address} and is from {patient_location}. Medical record number: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "    Performed on {scan_date}, the {scan_type} of the {body_part} for {name} (DOB {dob}) was indicated due to {indication}. \n",
    "    Interpretation by Dr. {doctor} at {imaging_center}, {center_location}, noted {findings}. \n",
    "    Impression summary: {impression}. \n",
    "    Patient's contact information: {phone}, {email}; residence: {address}, hometown: {patient_location}. MRN {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "    {scan_date} marked the date when {name} (born {dob}) underwent a {scan_type} focusing on the {body_part} owing to {indication}. \n",
    "    At {imaging_center} in {center_location}, Dr. {doctor} analyzed the images and reported {findings}. \n",
    "    The impression was characterized as {impression}. \n",
    "    You may contact the patient at {phone} or {email}. They live at {address} and originally come from {patient_location}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "    A diagnostic procedure was carried out on {scan_date} — a {scan_type} of the {body_part} for {name} (DOB {dob}) because of {indication}. \n",
    "    Dr. {doctor} at {imaging_center} ({center_location}) reviewed the scan, revealing {findings}. \n",
    "    Final impression reads: {impression}. \n",
    "    Contact details: phone {phone}, email {email}. Patient’s address: {address}. Origin: {patient_location}. MRN: {mrn}.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans with entity categories:\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (imaging_center, \"HOSPITAL\"),\n",
    "        (center_location, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n",
    "\n",
    "def generate_100_ct_reports():\n",
    "    return [generate_ct_scan_report() for _ in range(100)]\n",
    "\n",
    "# Example usage:\n",
    "all_ct_reports = generate_100_ct_reports()\n",
    "print(all_ct_reports[0][\"text\"])\n",
    "print(all_ct_reports[0][\"entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2293801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "def random_date(start, end):\n",
    "    \"\"\"Generate a random date between start and end (datetime objects).\"\"\"\n",
    "    delta = end - start\n",
    "    random_days = random.randint(0, delta.days)\n",
    "    return start + timedelta(days=random_days)\n",
    "\n",
    "def generate_admission_discharge_dates():\n",
    "    start_admission = datetime(2024, 1, 1)\n",
    "    end_admission = datetime(2025, 4, 30)\n",
    "    admission_date = random_date(start_admission, end_admission)\n",
    "\n",
    "    # Discharge date between 1 and 14 days after admission\n",
    "    discharge_date = admission_date + timedelta(days=random.randint(1, 14))\n",
    "\n",
    "    # Format dates as \"Month day, year\"\n",
    "    admission_str = admission_date.strftime(\"%B %d, %Y\")\n",
    "    discharge_str = discharge_date.strftime(\"%B %d, %Y\")\n",
    "\n",
    "    return admission_str, discharge_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09dfba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_summary(name, dob, diagnosis, treatment, follow_up):\n",
    "    admission_date, discharge_date = generate_admission_discharge_dates()\n",
    "    diagnoses = [\n",
    "        \"community-acquired pneumonia\",\n",
    "        \"acute myocardial infarction\",\n",
    "        \"exacerbation of chronic obstructive pulmonary disease\",\n",
    "        \"post-operative recovery following appendectomy\"\n",
    "    ]\n",
    "    treatments = [\n",
    "        \"antibiotic therapy and supportive care\",\n",
    "        \"percutaneous coronary intervention and medical management\",\n",
    "        \"bronchodilator therapy with steroids\",\n",
    "        \"laparoscopic appendectomy and pain control\"\n",
    "    ]\n",
    "    follow_ups = [\n",
    "        \"follow-up with primary care physician in 1 week\",\n",
    "        \"cardiology follow-up scheduled in 2 weeks\",\n",
    "        \"pulmonology appointment recommended in 1 month\",\n",
    "        \"surgical follow-up planned in 10 days\"\n",
    "    ]\n",
    "\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=20, maximum_age=90).strftime(\"%B %d, %Y\")\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    mrn = fake.bothify(text=\"MRN-#####\")\n",
    "\n",
    "    admission_date = random.choice(admission_date)\n",
    "    discharge_date = random.choice(discharge_date)\n",
    "    diagnosis = random.choice(diagnoses)\n",
    "    treatment = random.choice(treatments)\n",
    "    follow_up = random.choice(follow_ups)\n",
    "\n",
    "    templates = [\n",
    "    f\"\"\"\n",
    "    {name} was admitted to City Hospital on {admission_date} presenting with {diagnosis}. \n",
    "    The treatment protocol included {treatment}, leading to clinical improvement. \n",
    "    Discharge occurred on {discharge_date} with instructions for {follow_up}. \n",
    "    The patient was counseled to seek immediate care if symptoms worsen.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    On {admission_date}, {name} (DOB: {dob}) was admitted for management of {diagnosis}. \n",
    "    Following {treatment}, the patient showed satisfactory progress and was discharged on {discharge_date}. \n",
    "    Recommended follow-up: {follow_up}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    {name}’s hospital stay spanned from {admission_date} to {discharge_date} for treatment of {diagnosis}. \n",
    "    Clinical interventions included {treatment}. \n",
    "    At discharge, the patient received guidance on {follow_up} and symptom vigilance.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    The patient, {name}, was admitted with a diagnosis of {diagnosis} and received {treatment}. \n",
    "    Discharge on {discharge_date} was uneventful. Follow-up plans involve {follow_up}. \n",
    "    Contact info available upon request.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    Admission date: {admission_date}. Discharge date: {discharge_date}. Patient {name} treated for {diagnosis} via {treatment}. \n",
    "    Advised to maintain follow-up with {follow_up} and report any new or worsening symptoms promptly.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    {name} was hospitalized from {admission_date} to {discharge_date} for {diagnosis}. \n",
    "    The clinical team provided {treatment}. \n",
    "    Upon discharge, arrangements for {follow_up} were made.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    Between {admission_date} and {discharge_date}, {name} underwent inpatient care for {diagnosis}. \n",
    "    Treatment involved {treatment}. Discharge instructions emphasized {follow_up} and self-monitoring.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    Hospitalized patient {name} received care for {diagnosis} from {admission_date} until discharge on {discharge_date}. \n",
    "    Therapeutic approach was {treatment}. Post-discharge follow-up includes {follow_up}.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    Patient {name} presented on {admission_date} with {diagnosis}. \n",
    "    Management included {treatment}, with discharge on {discharge_date}. \n",
    "    Follow-up plans: {follow_up}. The patient was advised to contact their provider if symptoms change.\n",
    "    \"\"\",\n",
    "\n",
    "    f\"\"\"\n",
    "    {name} (DOB: {dob}) was admitted for {diagnosis}. The hospital course included {treatment}. \n",
    "    Discharge was on {discharge_date} with follow-up instructions: {follow_up}.\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans with entity categories:\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (admission_date, \"DATE\"),\n",
    "        (discharge_date, \"DATE\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8690c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suburban Diagnostic Clinic (789 Scan Rd, Townsville, State) performed an X-ray on 1980-12-08 for patient Scott Tran (DOB July 05, 1935) focused on the right wrist due to persistent cough. \n",
      "        The radiologist, Dr. Brendan Johnson, reported mild degenerative changes with an impression of degenerative joint disease. \n",
      "        Patient contact info: phone 001-736-565-4730x91028, email willischristopher@example.org. Address: 50171 Randall Hills, West Brendan, MI 76844, hometown: Lakeside. MRN MRN-55131.\n",
      "[{'start': 105, 'end': 115, 'label': 'NAME', 'text': 'Scott Tran'}, {'start': 121, 'end': 134, 'label': 'DATE', 'text': 'July 05, 1935'}, {'start': 218, 'end': 233, 'label': 'NAME', 'text': 'Brendan Johnson'}, {'start': 427, 'end': 470, 'label': 'LOCATION', 'text': '50171 Randall Hills, West Brendan, MI 76844'}, {'start': 0, 'end': 26, 'label': 'HOSPITAL', 'text': 'Suburban Diagnostic Clinic'}, {'start': 28, 'end': 58, 'label': 'LOCATION', 'text': '789 Scan Rd, Townsville, State'}, {'start': 496, 'end': 505, 'label': 'ID', 'text': 'MRN-55131'}, {'start': 357, 'end': 379, 'label': 'CONTACT', 'text': '001-736-565-4730x91028'}, {'start': 387, 'end': 416, 'label': 'CONTACT', 'text': 'willischristopher@example.org'}]\n"
     ]
    }
   ],
   "source": [
    "def generate_xray_report():\n",
    "    imaging_centers = [\n",
    "        (\"Metro Radiology Center\", \"123 Xray Lane, Metropolis, State\"),\n",
    "        (\"Downtown Imaging Facility\", \"456 Radiology Blvd, Cityville, State\"),\n",
    "        (\"Suburban Diagnostic Clinic\", \"789 Scan Rd, Townsville, State\"),\n",
    "        (\"Central Medical Imaging\", \"101 Health Ave, Metrocity, State\"),\n",
    "    ]\n",
    "\n",
    "    patient_locations = [\n",
    "        \"Metropolis\",\n",
    "        \"Cityville\",\n",
    "        \"Townsville\",\n",
    "        \"Metrocity\",\n",
    "        \"Lakeside\",\n",
    "        \"Hilltown\"\n",
    "    ]\n",
    "\n",
    "    imaging_center, center_location = random.choice(imaging_centers)\n",
    "    patient_location = random.choice(patient_locations)\n",
    "\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=20, maximum_age=90).strftime(\"%B %d, %Y\")\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    mrn = fake.bothify(text=\"MRN-#####\")\n",
    "    scan_date = fake.date()\n",
    "\n",
    "    body_part = random.choice([\"chest\", \"right wrist\", \"left ankle\", \"lumbar spine\"])\n",
    "    indication = random.choice([\n",
    "        \"suspected fracture after trauma\",\n",
    "        \"persistent cough\",\n",
    "        \"chronic lower back pain\",\n",
    "        \"evaluation of joint swelling\"\n",
    "    ])\n",
    "    findings = random.choice([\n",
    "        \"no acute fracture or dislocation\",\n",
    "        \"mild degenerative changes\",\n",
    "        \"evidence of soft tissue swelling\",\n",
    "        \"normal bone alignment and density\"\n",
    "    ])\n",
    "    impression = random.choice([\n",
    "        \"normal radiographic study\",\n",
    "        \"degenerative joint disease\",\n",
    "        \"soft tissue injury without fracture\",\n",
    "        \"no acute osseous abnormalities\"\n",
    "    ])\n",
    "\n",
    "    templates = [\n",
    "        f\"\"\"\n",
    "        On {scan_date}, {name} (DOB: {dob}) underwent an X-ray of the {body_part} at {imaging_center}, located in {center_location}. \n",
    "        The indication for the exam was {indication}. \n",
    "        Findings included {findings}. Impression: {impression}. \n",
    "        Report signed by Dr. {doctor}. Patient resides at {address}, from {patient_location}. Contact: {phone}, {email}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "        {imaging_center} ({center_location}) performed an X-ray on {scan_date} for patient {name} (DOB {dob}) focused on the {body_part} due to {indication}. \n",
    "        The radiologist, Dr. {doctor}, reported {findings} with an impression of {impression}. \n",
    "        Patient contact info: phone {phone}, email {email}. Address: {address}, hometown: {patient_location}. MRN {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "        Patient {name}, born {dob}, had an X-ray examination of the {body_part} on {scan_date} for {indication}. \n",
    "        Dr. {doctor} at {imaging_center} reviewed the images, noting {findings}. Impression was {impression}. \n",
    "        The patient can be contacted at {phone} or {email} and lives at {address} in {patient_location}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        f\"\"\"\n",
    "        An X-ray study of the {body_part} was performed on {scan_date} for {name} (DOB {dob}) at {imaging_center}, {center_location}. \n",
    "        The clinical indication was {indication}. Findings reported by Dr. {doctor} included {findings} with an impression of {impression}. \n",
    "        Contact details: {phone}, {email}. Residence: {address}, hometown: {patient_location}. MRN: {mrn}.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans with entity categories:\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (imaging_center, \"HOSPITAL\"),\n",
    "        (center_location, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n",
    "\n",
    "\n",
    "def generate_100_xray_reports():\n",
    "    return [generate_xray_report() for _ in range(100)]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "all_xray_reports = generate_100_xray_reports()\n",
    "print(all_xray_reports[0][\"text\"])\n",
    "print(all_xray_reports[0][\"entities\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e882ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2001-03-22, Dale Jackson (DOB March 28, 1983) underwent an MRI examination focusing on the brain, prompted by low back pain radiating to legs. \n",
      "    The study was performed at Neuro Imaging Center in 123 Brain St, Metropolis, State. Dr. Sheryl Carter carefully reviewed the images and documented the following:\n",
      "\n",
      "    Findings reveal rotator cuff tendinopathy with mild bursitis. The overall impression is rotator cuff tendinopathy, clinical correlation advised. \n",
      "\n",
      "    For further inquiries or follow-up, please contact the patient at +1-649-252-4358x8143 or charlescaldwell@example.com. \n",
      "    Patient resides at 26661 Horton Ford, Hollandmouth, VA 72402, registered under MRN MRN-92491, currently located in Hilltown.\n",
      "[{'start': 15, 'end': 27, 'label': 'NAME', 'text': 'Dale Jackson'}, {'start': 33, 'end': 47, 'label': 'DATE', 'text': 'March 28, 1983'}, {'start': 239, 'end': 252, 'label': 'NAME', 'text': 'Sheryl Carter'}, {'start': 612, 'end': 653, 'label': 'LOCATION', 'text': '26661 Horton Ford, Hollandmouth, VA 72402'}, {'start': 178, 'end': 198, 'label': 'HOSPITAL', 'text': 'Neuro Imaging Center'}, {'start': 202, 'end': 233, 'label': 'LOCATION', 'text': '123 Brain St, Metropolis, State'}, {'start': 676, 'end': 685, 'label': 'ID', 'text': 'MRN-92491'}, {'start': 535, 'end': 555, 'label': 'CONTACT', 'text': '+1-649-252-4358x8143'}, {'start': 559, 'end': 586, 'label': 'CONTACT', 'text': 'charlescaldwell@example.com'}, {'start': 708, 'end': 716, 'label': 'LOCATION', 'text': 'Hilltown'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_mri_report():\n",
    "    imaging_centers = [\n",
    "        (\"Neuro Imaging Center\", \"123 Brain St, Metropolis, State\"),\n",
    "        (\"Orthopedic MRI Clinic\", \"456 Joint Blvd, Townsville, State\"),\n",
    "        (\"Spine & Sports MRI Facility\", \"789 Spine Rd, Villagetown, State\"),\n",
    "        (\"Advanced MRI Center\", \"101 Scan Ave, Metrocity, State\"),\n",
    "    ]\n",
    "\n",
    "    patient_locations = [\n",
    "        \"Metropolis\",\n",
    "        \"Townsville\",\n",
    "        \"Villagetown\",\n",
    "        \"Metrocity\",\n",
    "        \"Lakeside\",\n",
    "        \"Hilltown\"\n",
    "    ]\n",
    "\n",
    "    imaging_center, center_location = random.choice(imaging_centers)\n",
    "    patient_location = random.choice(patient_locations)\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=20, maximum_age=90).strftime(\"%B %d, %Y\")\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    mrn = fake.bothify(text=\"MRN-#####\")\n",
    "    scan_date = fake.date()\n",
    "    body_part = random.choice([\"brain\", \"knee\", \"lumbar spine\", \"shoulder\"])\n",
    "    indication = random.choice([\n",
    "        \"evaluation of chronic headaches\",\n",
    "        \"suspected ligament injury\",\n",
    "        \"low back pain radiating to legs\",\n",
    "        \"persistent shoulder pain post injury\"\n",
    "    ])\n",
    "    findings = random.choice([\n",
    "        \"no acute intracranial abnormalities\",\n",
    "        \"partial tear of the anterior cruciate ligament\",\n",
    "        \"degenerative disc disease at L4-L5\",\n",
    "        \"rotator cuff tendinopathy with mild bursitis\"\n",
    "    ])\n",
    "    impression = random.choice([\n",
    "        \"normal MRI study\",\n",
    "        \"findings consistent with ACL partial tear\",\n",
    "        \"degenerative changes contributing to symptoms\",\n",
    "        \"rotator cuff tendinopathy, clinical correlation advised\"\n",
    "    ])\n",
    "\n",
    "    templates = [\n",
    "    # Narrative style with patient story feel\n",
    "    f\"\"\"\n",
    "    Patient {name}, born {dob}, presented for MRI of the {body_part} on {scan_date} due to {indication}. \n",
    "    Dr. {doctor} evaluated the images obtained at {imaging_center} ({center_location}). \n",
    "    Key findings noted were: {findings}. Impression: {impression}. \n",
    "    Contact: {phone} | {email}. Address: {address}. MRN: {mrn}. Location: {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    # Bulleted summary style\n",
    "    f\"\"\"\n",
    "    MRI Report Summary:\n",
    "    - Patient: {name} (DOB: {dob})\n",
    "    - Exam Date: {scan_date}\n",
    "    - Body Part: {body_part}\n",
    "    - Clinical Indication: {indication}\n",
    "    - Facility: {imaging_center}, {center_location}\n",
    "    - Interpreting Radiologist: Dr. {doctor}\n",
    "\n",
    "    Findings:\n",
    "    * {findings}\n",
    "\n",
    "    Impression:\n",
    "    * {impression}\n",
    "\n",
    "    Patient Contact Information:\n",
    "    Phone: {phone}\n",
    "    Email: {email}\n",
    "    Address: {address}\n",
    "    MRN: {mrn}\n",
    "    Patient Location: {patient_location}\n",
    "    \"\"\",\n",
    "\n",
    "    # Conversational, more detailed description\n",
    "    f\"\"\"\n",
    "    On {scan_date}, {name} (DOB {dob}) underwent an MRI examination focusing on the {body_part}, prompted by {indication}. \n",
    "    The study was performed at {imaging_center} in {center_location}. Dr. {doctor} carefully reviewed the images and documented the following:\n",
    "    \n",
    "    Findings reveal {findings}. The overall impression is {impression}. \n",
    "\n",
    "    For further inquiries or follow-up, please contact the patient at {phone} or {email}. \n",
    "    Patient resides at {address}, registered under MRN {mrn}, currently located in {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    # Formal medical report style, compact paragraph\n",
    "    f\"\"\"\n",
    "    MRI of the {body_part} for {name} (DOB: {dob}) was conducted on {scan_date} at {imaging_center} ({center_location}) due to {indication}. \n",
    "    Interpretation by Dr. {doctor} demonstrated {findings}. Impression concludes: {impression}. \n",
    "    Contact details include phone {phone}, email {email}, residence {address}, MRN {mrn}, and patient location {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    # Mix with directive suggestions\n",
    "    f\"\"\"\n",
    "    {name} (DOB {dob}) underwent MRI scanning of the {body_part} on {scan_date} at {imaging_center}, {center_location}, due to {indication}. \n",
    "    Dr. {doctor} reported the following findings: {findings}. Impression: {impression}. \n",
    "    Clinical correlation is recommended to further evaluate these findings. \n",
    "    Patient contact info: {phone}, {email}. Residence: {address}. MRN: {mrn}. Location: {patient_location}.\n",
    "    \"\"\",\n",
    "\n",
    "    # Flow with slight variation and sentence breaks\n",
    "    f\"\"\"\n",
    "    MRI examination of the {body_part} was performed on {scan_date} for patient {name}, born {dob}. The indication for imaging was {indication}. \n",
    "    Images were acquired at {imaging_center} ({center_location}) and interpreted by Dr. {doctor}. \n",
    "    Findings included {findings}. Impression: {impression}. \n",
    "\n",
    "    For further details, contact patient at {phone} or {email}. Address: {address}. MRN: {mrn}. Current location: {patient_location}.\n",
    "    \"\"\"\n",
    "]\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans with entity categories:\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (imaging_center, \"HOSPITAL\"),\n",
    "        (center_location, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "        (patient_location, \"LOCATION\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n",
    "\n",
    "def generate_100_mri_reports():\n",
    "    return [generate_mri_report() for _ in range(100)]\n",
    "\n",
    "# Example usage:\n",
    "all_mri_reports = generate_100_mri_reports()\n",
    "print(all_mri_reports[0][\"text\"])\n",
    "print(all_mri_reports[0][\"entities\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f8e8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histology_report():\n",
    "    pathology_centers = [\n",
    "        (\"Central Pathology Lab\", \"100 Histology Rd, MedCity, State\"),\n",
    "        (\"Advanced Diagnostic Pathology\", \"250 Biopsy Ln, Healthville, State\"),\n",
    "        (\"Precision Tissue Diagnostics\", \"75 Microscopy Ave, Researchtown, State\"),\n",
    "        (\"Integrated Cancer Pathology Center\", \"500 Oncology Dr, Metrocity, State\"),\n",
    "    ]\n",
    "\n",
    "    patient_locations = [\n",
    "        \"MedCity\",\n",
    "        \"Healthville\",\n",
    "        \"Researchtown\",\n",
    "        \"Metrocity\",\n",
    "        \"Lakeside\",\n",
    "        \"Hilltown\"\n",
    "    ]\n",
    "\n",
    "    pathology_center, center_location = random.choice(pathology_centers)\n",
    "    patient_location = random.choice(patient_locations)\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=90).strftime(\"%B %d, %Y\")\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    mrn = fake.bothify(text=\"MRN-#####\")\n",
    "    specimen = random.choice([\"breast biopsy\", \"colon polyp\", \"skin lesion\", \"lymph node excision\"])\n",
    "    diagnosis = random.choice([\n",
    "        \"benign fibrocystic changes\",\n",
    "        \"adenocarcinoma\",\n",
    "        \"basal cell carcinoma\",\n",
    "        \"reactive lymphoid hyperplasia\"\n",
    "    ])\n",
    "    comments = random.choice([\n",
    "        \"No evidence of malignancy.\",\n",
    "        \"Margins are clear of tumor.\",\n",
    "        \"Further immunohistochemical stains recommended.\",\n",
    "        \"Findings consistent with chronic inflammation.\"\n",
    "    ])\n",
    "    report_date = fake.date()\n",
    "\n",
    "    templates = [\n",
    "        # Narrative clinical report\n",
    "        f\"\"\"\n",
    "        Patient {name}, born {dob}, underwent histopathological examination of the {specimen} on {report_date} at {pathology_center} ({center_location}). \n",
    "        Dr. {doctor} reviewed the tissue sections and identified: {diagnosis}. {comments}\n",
    "        These findings are essential for guiding patient management and potential treatment planning.\n",
    "        Contact: {phone} | {email}. Address: {address}. MRN: {mrn}. Location: {patient_location}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Structured research summary\n",
    "        f\"\"\"\n",
    "        Histopathology Report:\n",
    "        - Patient: {name} (DOB: {dob})\n",
    "        - Specimen: {specimen}\n",
    "        - Date of Examination: {report_date}\n",
    "        - Facility: {pathology_center}, {center_location}\n",
    "        - Reporting Pathologist: Dr. {doctor}\n",
    "\n",
    "        Diagnosis:\n",
    "        * {diagnosis}\n",
    "\n",
    "        Additional Comments:\n",
    "        * {comments}\n",
    "\n",
    "        Patient Contact Information:\n",
    "        Phone: {phone}\n",
    "        Email: {email}\n",
    "        Address: {address}\n",
    "        MRN: {mrn}\n",
    "        Patient Location: {patient_location}\n",
    "        \"\"\",\n",
    "\n",
    "        # Concise clinical synopsis\n",
    "        f\"\"\"\n",
    "        On {report_date}, histological analysis of the {specimen} from patient {name} (DOB {dob}) was completed at {pathology_center} ({center_location}). \n",
    "        The pathological diagnosis was {diagnosis}. {comments} These results should be correlated with clinical findings for comprehensive care.\n",
    "        For follow-up, contact {phone} or {email}. Patient resides at {address}. MRN: {mrn}. Current location: {patient_location}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Diagnostic statement with clinical recommendations\n",
    "        f\"\"\"\n",
    "        The {specimen} obtained from {name} (DOB {dob}) was examined on {report_date} at {pathology_center} by Dr. {doctor}. \n",
    "        Diagnosis: {diagnosis}. {comments} Further molecular or immunohistochemical analyses may be warranted to confirm findings and inform therapeutic decisions.\n",
    "        Contact information: Phone {phone}, Email {email}, Address {address}, MRN {mrn}, Location {patient_location}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Research brief for clinical study context\n",
    "        f\"\"\"\n",
    "        Patient {name} (DOB {dob}) submitted a {specimen} for histopathological evaluation on {report_date} at {pathology_center}, {center_location}. \n",
    "        Dr. {doctor} reported {diagnosis} with observations noting: {comments}. These data contribute to clinical research and patient management protocols.\n",
    "        Contact: {phone} | {email} | {address}. MRN: {mrn}. Patient Location: {patient_location}.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans with entity categories\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (pathology_center, \"HOSPITAL\"),\n",
    "        (center_location, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "        (patient_location, \"LOCATION\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f8d6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_surgery_report():\n",
    "    procedures = [\n",
    "        \"laparoscopic cholecystectomy\",\n",
    "        \"open appendectomy\",\n",
    "        \"knee arthroscopy\",\n",
    "        \"thyroidectomy\"\n",
    "    ]\n",
    "    \n",
    "    indications = [\n",
    "        \"symptomatic cholelithiasis\",\n",
    "        \"acute suppurative appendicitis\",\n",
    "        \"medial meniscus tear\",\n",
    "        \"enlarging thyroid nodule with compressive symptoms\"\n",
    "    ]\n",
    "\n",
    "    findings_list = [\n",
    "        \"a distended, inflamed gallbladder with multiple cholesterol stones\",\n",
    "        \"a gangrenous appendix with surrounding purulent fluid\",\n",
    "        \"a complex tear of the medial meniscus with joint effusion\",\n",
    "        \"a multinodular thyroid with suspicious features under ultrasound\"\n",
    "    ]\n",
    "\n",
    "    complications_list = [\n",
    "        \"Procedure was completed without intraoperative complications.\",\n",
    "        \"Minimal bleeding encountered, managed effectively with bipolar cautery.\",\n",
    "        \"Extensive adhesions encountered, requiring sharp dissection.\",\n",
    "        \"Anatomical variations were present but navigated without incident.\"\n",
    "    ]\n",
    "\n",
    "    outcomes = [\n",
    "        \"Patient tolerated the procedure well and was transferred to the PACU in stable condition.\",\n",
    "        \"Surgical goals were achieved with no deviation from planned protocol.\",\n",
    "        \"Post-operative vitals were stable, and no immediate concerns were noted.\",\n",
    "        \"Wound closed with subcuticular sutures; hemostasis confirmed prior to closure.\"\n",
    "    ]\n",
    "\n",
    "    hospitals = [\n",
    "        (\"Mount Atlas Surgical Centre\", \"321 Recovery Blvd, Healthtown, State\"),\n",
    "        (\"Pineview General Hospital\", \"908 Wellness Way, Care City, State\"),\n",
    "        (\"Surgical Arts Pavilion\", \"150 Operation Ave, MediCity, State\"),\n",
    "        (\"North Ridge Medical Center\", \"45 Surgeon St, Vitalville, State\")\n",
    "    ]\n",
    "\n",
    "    # Random Selections\n",
    "    procedure = random.choice(procedures)\n",
    "    indication = random.choice(indications)\n",
    "    findings = random.choice(findings_list)\n",
    "    complications = random.choice(complications_list)\n",
    "    outcome = random.choice(outcomes)\n",
    "    hospital_name, hospital_address = random.choice(hospitals)\n",
    "\n",
    "    # Patient & Doctor Info\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=85).strftime(\"%B %d, %Y\")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    mrn = fake.bothify(text=\"MRN-#####\")\n",
    "    surgery_date = fake.date()\n",
    "\n",
    "    templates = [\n",
    "        # Narrative operative summary\n",
    "        f\"\"\"\n",
    "        On {surgery_date}, patient {name} (DOB: {dob}) underwent a {procedure} at {hospital_name} ({hospital_address}) for {indication}. \n",
    "        Intraoperatively, {findings} were noted by the attending surgeon, Dr. {doctor}. \n",
    "        {complications} {outcome}\n",
    "        For follow-up or questions, please contact {phone} or email {email}. Patient address: {address}, MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Structured case report\n",
    "        f\"\"\"\n",
    "        Operative Report\n",
    "        -----------------\n",
    "        Patient Name: {name}\n",
    "        Date of Birth: {dob}\n",
    "        MRN: {mrn}\n",
    "        Date of Procedure: {surgery_date}\n",
    "        Surgeon: Dr. {doctor}\n",
    "        Facility: {hospital_name}, {hospital_address}\n",
    "\n",
    "        Procedure: {procedure}\n",
    "        Indication: {indication}\n",
    "        Findings: {findings}\n",
    "        Complications: {complications}\n",
    "        Outcome: {outcome}\n",
    "\n",
    "        Contact Info:\n",
    "        Phone: {phone}\n",
    "        Email: {email}\n",
    "        Address: {address}\n",
    "        \"\"\",\n",
    "\n",
    "        # Clinical vignette format\n",
    "        f\"\"\"\n",
    "        Patient {name}, a {random.randint(25, 78)}-year-old individual, presented with {indication} and was taken to the OR for a {procedure} on {surgery_date}. \n",
    "        The surgical team at {hospital_name} led by Dr. {doctor} identified {findings} during the procedure. \n",
    "        {complications} {outcome} The patient resides at {address}. Contact via phone: {phone}, or email: {email}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Academic conference summary\n",
    "        f\"\"\"\n",
    "        Case Summary:\n",
    "        - Patient: {name} ({dob})\n",
    "        - Procedure: {procedure}\n",
    "        - Indication: {indication}\n",
    "        - Findings: {findings}\n",
    "        - Complications: {complications}\n",
    "        - Outcome: {outcome}\n",
    "        - Surgeon: Dr. {doctor}\n",
    "        - Date: {surgery_date}\n",
    "        - Facility: {hospital_name}, {hospital_address}\n",
    "\n",
    "        For further discussion or data access, contact {phone} | {email}. MRN: {mrn}, Address: {address}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Discharge note excerpt\n",
    "        f\"\"\"\n",
    "        Discharge Note:\n",
    "        {name} (DOB {dob}) underwent a successful {procedure} on {surgery_date} at {hospital_name}, indicated for {indication}. \n",
    "        Intraoperative findings included: {findings}. {complications} {outcome}\n",
    "        Discharge instructions provided. Contact: {phone} | {email}, MRN: {mrn}, Address: {address}.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (hospital_name, \"HOSPITAL\"),\n",
    "        (hospital_address, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f06914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_lab_report():\n",
    "    test_types = [\n",
    "        \"complete blood count (CBC)\",\n",
    "        \"basic metabolic panel (BMP)\",\n",
    "        \"lipid panel\",\n",
    "        \"coagulation profile\",\n",
    "        \"liver function test (LFT)\",\n",
    "        \"thyroid-stimulating hormone (TSH) panel\"\n",
    "    ]\n",
    "\n",
    "    indications = [\n",
    "        \"routine annual health assessment\",\n",
    "        \"persistent fatigue and dizziness\",\n",
    "        \"renal function monitoring in chronic kidney disease\",\n",
    "        \"assessment of lipid levels due to family history of cardiovascular disease\",\n",
    "        \"evaluation of liver enzymes due to suspected hepatitis\",\n",
    "        \"thyroid dysfunction symptoms including weight gain and cold intolerance\"\n",
    "    ]\n",
    "\n",
    "    findings_list = [\n",
    "        \"values within expected physiological range\",\n",
    "        \"microcytic anemia with decreased hemoglobin and hematocrit\",\n",
    "        \"elevated creatinine and reduced eGFR indicating Stage 2 CKD\",\n",
    "        \"LDL cholesterol above optimal limits with low HDL\",\n",
    "        \"elevated ALT and AST consistent with hepatocellular injury\",\n",
    "        \"elevated TSH with low T3 and T4 suggesting primary hypothyroidism\"\n",
    "    ]\n",
    "\n",
    "    impressions = [\n",
    "        \"No clinically significant abnormalities identified.\",\n",
    "        \"Anemia consistent with iron deficiency; further evaluation recommended.\",\n",
    "        \"Renal insufficiency suspected—nephrology referral suggested.\",\n",
    "        \"Hyperlipidemia noted; dietary modification and statin therapy advised.\",\n",
    "        \"Liver function derangement suggestive of mild hepatic inflammation.\",\n",
    "        \"Thyroid profile supports diagnosis of hypothyroidism; endocrinology consult may be beneficial.\"\n",
    "    ]\n",
    "\n",
    "    # Random selections\n",
    "    test_type = random.choice(test_types)\n",
    "    indication = random.choice(indications)\n",
    "    findings = random.choice(findings_list)\n",
    "    impression = random.choice(impressions)\n",
    "\n",
    "    # Patient & Doctor Info\n",
    "    name = fake.name()\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=85).strftime(\"%B %d, %Y\")\n",
    "    doctor = fake.name()\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    mrn = fake.bothify(text=\"MRN-#####\")\n",
    "    scan_date = fake.date()\n",
    "\n",
    "    templates = [\n",
    "        # Clinical summary style\n",
    "        f\"\"\"\n",
    "        Patient {name} (DOB: {dob}) underwent a {test_type} on {scan_date} due to {indication}. \n",
    "        Laboratory results were interpreted by Dr. {doctor} and revealed the following: {findings}. \n",
    "        Impression: {impression}. For inquiries, reach out at {phone} or email {email}. Address: {address}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Progress note style\n",
    "        f\"\"\"\n",
    "        Date: {scan_date}\n",
    "        Patient: {name} (DOB: {dob}) | MRN: {mrn}\n",
    "        Test Performed: {test_type}\n",
    "        Indication: {indication}\n",
    "        Findings: {findings}\n",
    "        Impression: {impression}\n",
    "        Ordering Physician: Dr. {doctor}\n",
    "        Contact: {phone}, {email}\n",
    "        Residence: {address}\n",
    "        \"\"\",\n",
    "\n",
    "        # Research-style narrative\n",
    "        f\"\"\"\n",
    "        As part of routine diagnostics on {scan_date}, {name} (born {dob}) had a {test_type} performed to investigate {indication}. \n",
    "        Results revealed {findings}. The impression provided by Dr. {doctor} indicated: {impression}. \n",
    "        For medical records or inquiries, the patient can be contacted via phone ({phone}) or email ({email}). Home address: {address}. MRN: {mrn}.\n",
    "        \"\"\",\n",
    "\n",
    "        # Academic abstract style\n",
    "        f\"\"\"\n",
    "        Case: {name} (DOB: {dob}), MRN: {mrn}\n",
    "        Test: {test_type}\n",
    "        Indication: {indication}\n",
    "        Findings: {findings}\n",
    "        Impression: {impression}\n",
    "        Performed on: {scan_date} | Interpreting Clinician: Dr. {doctor}\n",
    "        Contact: {phone} | {email}\n",
    "        Address: {address}\n",
    "        \"\"\",\n",
    "\n",
    "        # Discharge lab summary style\n",
    "        f\"\"\"\n",
    "        Lab Summary: On {scan_date}, {name} (DOB {dob}) underwent a {test_type} in context of {indication}. \n",
    "        Notable results: {findings}. Interpreting physician, Dr. {doctor}, noted: {impression}. \n",
    "        MRN: {mrn}. Contact details include {phone} and {email}. Patient resides at {address}.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    template = random.choice(templates).strip()\n",
    "\n",
    "    # Annotate PHI spans\n",
    "    entities = []\n",
    "    for ent_text, label in [\n",
    "        (name, \"NAME\"),\n",
    "        (dob, \"DATE\"),\n",
    "        (doctor, \"NAME\"),\n",
    "        (address, \"LOCATION\"),\n",
    "        (mrn, \"ID\"),\n",
    "        (phone, \"CONTACT\"),\n",
    "        (email, \"CONTACT\"),\n",
    "    ]:\n",
    "        start = template.find(ent_text)\n",
    "        if start != -1:\n",
    "            end = start + len(ent_text)\n",
    "            entities.append({\"start\": start, \"end\": end, \"label\": label, \"text\": ent_text})\n",
    "\n",
    "    return {\"text\": template, \"entities\": entities}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08ee5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_and_return_reports_df():\n",
    "    report_generators = {\n",
    "        \"Lab Report\": lambda: generate_lab_report(),\n",
    "        \"MRI Report\": lambda: generate_mri_report(),\n",
    "        \"X-ray Report\": lambda: generate_xray_report(),\n",
    "        \"Mammography Report\": lambda: generate_mammography_report(),\n",
    "        \"Summary Report\": lambda: generate_summary(\n",
    "            name=fake.name(),\n",
    "            dob=fake.date_of_birth(minimum_age=18, maximum_age=85).strftime(\"%B %d, %Y\"),\n",
    "            diagnosis=random.choice([\"hypertension\", \"type 2 diabetes\", \"osteoarthritis\"]),\n",
    "            treatment=random.choice([\"lifestyle modification\", \"metformin\", \"physical therapy\"]),\n",
    "            follow_up=random.choice([\"follow-up in 6 months\", \"monthly check-ins\", \"specialist referral\"])\n",
    "        ),\n",
    "        \"CT Scan Report\": lambda: generate_ct_scan_report(),\n",
    "        \"Surgery Report\": lambda: generate_surgery_report(),\n",
    "        \"Histology Report\": lambda: generate_histology_report(),\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for report_type, generator in report_generators.items():\n",
    "        reports = [generator() for _ in range(100)]\n",
    "        for report in reports:\n",
    "            rows.append({\n",
    "                \"report_type\": report_type,\n",
    "                \"text\": report[\"text\"],\n",
    "                \"entities\": report[\"entities\"]\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b863c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports = generate_and_return_reports_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cc22d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports.to_csv(\"generated_reports.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf51c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model name value is unexpected. Only support XLNet and GPT2 model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Suppose df is your original DataFrame with a 'text' column\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Example: df = generate_and_return_reports_df()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m paraphraser = \u001b[43mnas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mContextualWordEmbsForSentenceAug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbert-base-uncased\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maugment_dataframe_texts\u001b[39m(df, text_column=\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m, n_aug=\u001b[32m3\u001b[39m):\n\u001b[32m     10\u001b[39m     augmented_rows = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lora/lor_venv/lib/python3.11/site-packages/nlpaug/augmenter/sentence/context_word_embs_sentence.py:88\u001b[39m, in \u001b[36mContextualWordEmbsForSentenceAug.__init__\u001b[39m\u001b[34m(self, model_path, model_type, name, min_length, max_length, batch_size, temperature, top_k, top_p, device, force_reload, silence, use_custom_api)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.model_type = model_type \u001b[38;5;28;01mif\u001b[39;00m model_type != \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_model_type() \n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.use_custom_api = use_custom_api\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilence\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_custom_api\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_custom_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28mself\u001b[39m.device = \u001b[38;5;28mself\u001b[39m.model.device\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lora/lor_venv/lib/python3.11/site-packages/nlpaug/augmenter/sentence/context_word_embs_sentence.py:202\u001b[39m, in \u001b[36mContextualWordEmbsForSentenceAug.get_model\u001b[39m\u001b[34m(cls, model_path, model_type, device, force_reload, min_length, max_length, batch_size, temperature, top_k, top_p, silence, use_custom_api)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, model_path, model_type, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, force_reload=\u001b[38;5;28;01mFalse\u001b[39;00m, min_length=\u001b[32m100\u001b[39m, \n\u001b[32m    200\u001b[39m     max_length=\u001b[32m300\u001b[39m, batch_size=\u001b[32m32\u001b[39m, temperature=\u001b[32m1.0\u001b[39m, top_k=\u001b[32m50\u001b[39m, top_p=\u001b[32m0.9\u001b[39m, silence=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m    201\u001b[39m     use_custom_api=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_context_word_embs_sentence_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilence\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_custom_api\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_custom_api\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lora/lor_venv/lib/python3.11/site-packages/nlpaug/augmenter/sentence/context_word_embs_sentence.py:41\u001b[39m, in \u001b[36minit_context_word_embs_sentence_model\u001b[39m\u001b[34m(model_path, model_type, device, force_reload, min_length, max_length, batch_size, temperature, top_k, top_p, silence, use_custom_api)\u001b[39m\n\u001b[32m     38\u001b[39m         model = nml.Gpt2(model_path, device=device, temperature=temperature, top_k=top_k, \n\u001b[32m     39\u001b[39m                          optimize=\u001b[38;5;28;01mNone\u001b[39;00m, silence=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mModel name value is unexpected. Only support XLNet and GPT2 model.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     43\u001b[39m     model = nml.TextGenTransformers(model_path, device=device, min_length=min_length, max_length=max_length, \n\u001b[32m     44\u001b[39m         temperature=temperature, top_k=top_k, top_p=top_p, batch_size=batch_size)\n",
      "\u001b[31mValueError\u001b[39m: Model name value is unexpected. Only support XLNet and GPT2 model."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "def augment_dataframe_texts(df, text_column='text', n_aug=3):\n",
    "    augmented_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        original_text = row[text_column]\n",
    "        try:\n",
    "            aug_texts = paraphraser.augment(original_text, n=n_aug)\n",
    "            for aug_text in aug_texts:\n",
    "                # Copy the original row data if you want to keep other columns too\n",
    "                new_row = row.copy()\n",
    "                new_row[text_column] = aug_text\n",
    "                augmented_rows.append(new_row)\n",
    "        except Exception as e:\n",
    "            # On failure, optionally add the original row or skip\n",
    "            # Here, we skip silently, but you can log if you want\n",
    "            continue\n",
    "\n",
    "    # Create a new DataFrame from augmented rows\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    return augmented_df\n",
    "\n",
    "# Usage:\n",
    "augmented_df = augment_dataframe_texts(all_reports)\n",
    "print(augmented_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504f85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lor_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
